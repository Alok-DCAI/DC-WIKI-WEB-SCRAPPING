{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "hTAwWJ5Qlmwk"
   },
   "source": [
    "<img src=\"https://drive.google.com/uc?export=view&id=1Krpv420Trw6HQbArLSzrbYcpBz-9wgxw\" width=250/>\n",
    "\n",
    "# Data Engineering\n",
    "## Assignment 1: Webscraping wikipedia's Billboard pages\n",
    "\n",
    "**Alok K Pandey**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYXK8VrcW9Mg"
   },
   "source": [
    "## Instructions <a class=\"anchor\" id=\"instructions\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbPCzlmxXh2w"
   },
   "source": [
    "<hr style=\"height:2pt\">\n",
    "\n",
    "\n",
    "# Task 1: Constructing a year-song dataframe\n",
    "\n",
    "**Question 1:** Scrape and Parse Wikipedia for Billboard's Top 100 songs starting from 1992 to 2021.\n",
    "\n",
    "**1.1** Scrape Wikipedia's Billboard pages from 1992 to 2021.\n",
    "\n",
    "<details>\n",
    "\n",
    "- Use python's `requests` module to obtain (GET) the web pages at http://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_1992, http://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_1993 till http://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_2021.\n",
    "\n",
    "- Store the text from your `requests` in a dictionary called `yearstext`. \n",
    "This dictionary should have as its keys the years (as integers from 1992 to 2021), and as values corresponding to these keys the text of the page being fetched.\n",
    "\n",
    "*Hint:* Put your requests.get() in a `for` loop and use the `time.sleep` function to wait one second between requests, you do not want Wikipedia to think you are a marauding bot attempting to mount a denial-of-service attack.\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "**1.2** Parse the HTML retrieved to extract ranking, song and artist information. \n",
    "\n",
    "  **Note:** Here are some other issues that you will need to take care of while parsing:\n",
    "\n",
    "<details>\n",
    "    \n",
    "    i. The example shown above has several artists for a single song. In this case, the `band_singer` and `url` would be a list of items.\n",
    "\n",
    "    ii. Some singles might even have multiple songs because of the way the industry works:\n",
    "    ```\n",
    "    {'ranking': 98,\n",
    "    'song': [\"You're Makin' Me High\", 'Let It Flow (song)'],\n",
    "    'songurl': ['/wiki/You%27re_Makin%27_Me_High', '/wiki/Let_It_Flow_(song)'],\n",
    "    'titletext': '\"You\\'re Makin\\' Me High\" / \"Let It Flow\"',\n",
    "    'band_singer': ['Toni Braxton'],\n",
    "    'url': ['/wiki/Toni_Braxton']}\n",
    "    ```\n",
    "    (See 1997 for an example)\n",
    "\n",
    "    iii. Some songs don't have a URL. In this case, assume there is one song in the single, set `songurl` to [`None`] and the song name to the contents of the table cell with the quotes stripped:\n",
    "    ```\n",
    "    {'ranking': 45,\n",
    "      'song': ['Say It'],\n",
    "      'songurl': [None],\n",
    "      'titletext': '\"Say It\"',\n",
    "      'band_singer': ['Voices of Theory'],\n",
    "      'url': ['/wiki/Voices_of_Theory']}\n",
    "    ```\n",
    "    (See 1998 for an example)\n",
    "\n",
    "</details>\n",
    "<br>\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 358,
     "status": "ok",
     "timestamp": 1653658404318,
     "user": {
      "displayName": "Arya Mohan",
      "userId": "15606194433450766788"
     },
     "user_tz": -330
    },
    "id": "deZ11vb4lm3e",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# libraries to get you started\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "044UilQrsU_x"
   },
   "source": [
    "* Hint: Save the obtained dictionary as a json file so you do not need to run it over and over again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kd_0dzuslm7B"
   },
   "source": [
    "<hr style=\"height:2pt\">\n",
    "\n",
    "**Question 2:** Construct a DataFrame from parsed data\n",
    "\n",
    "**2.1** Construct a dataframe from the dictionary `yearinfo`.\n",
    "\n",
    "<details>\n",
    "    \n",
    "- Construct a dataframe from the dictionary created in the previous section `yearinfo`. Name this dataframe `billboardtop`.<br><br>\n",
    "  Keep in mind, in the data structure we have so far, a given key can have a list of values with multiple entries. Also, our data is grouped by year. So we need a way to flatten this data into a format that will create a useful DataFrame. \n",
    "  Your final dataframe `billboardtop` should look something like this:\n",
    "\n",
    "  <img src=\"https://drive.google.com/uc?export=view&id=1adDiuSmHXR7B7YO2ZNT_OJ9QejUyuJAC\" width=1500/>\n",
    "\n",
    "- Ensure that all lists in your dictionary are in different rows. <br>\n",
    "  For example, a single containing two artists should be two different rows:\n",
    "  <img src=\"https://drive.google.com/uc?export=view&id=1hxGXmP20vJ5i1N7WDg_pZBYly7gX2Gz0\" width=1500/>\n",
    "\n",
    "  A single containing two titles (1997, Rank 98) should be two different rows:\n",
    "  <img src=\"https://drive.google.com/uc?export=view&id=1nRrDQOixcH4HfahfA9YF7R7brm_OyD7d\" width=1500/>\n",
    "\n",
    "</details>\n",
    "\n",
    "**2.2** Check your dataframes data types and convert them to the correct data types if needed.\n",
    "\n",
    "- Check dataframe data types using ```dtypes```.\n",
    "- Convert them to the correct data types if needed using the ```astype()``` function.\n",
    "\n",
    "**2.3** Store this dataframe in ADLS so that you can use it for tasks ahead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hint: Use pickle to save you data, it retains your given datatypes and few other metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmtbYTjl8rR0"
   },
   "source": [
    "# Part B: Constructing a year-song-singer dataframe\n",
    "\n",
    "Now, we need to fetch information about the singers or bands for all the songs we have in the `billboardtop` dataframe.\n",
    "\n",
    "**Question 1:** Scrape and Parse Wikipedia for information about Artists and Bands\n",
    "\n",
    "**1.1** Scrape the artist's Wikipedia webpages.\n",
    "\n",
    "<details>\n",
    "\n",
    "Since we have hundreds of artists webpages to scrape, we have created a function which implements caching in order to speed up this process.\n",
    "\n",
    "The cache object urlcache that will avoid redundant HTTP requests (e.g. an artist might have multiple singles on a single year, or be on the list over a span of years). **Remember that this function is designed to be used in a loop over years, and then a loop over songs per year.** Since network requests are relatively slow, if we have already requested for a singer or band's wikipedia page, caching the results is a smart thing to do.\n",
    "\n",
    "Notice that we have wrapped the call in an exception block. If the request gets an HTTP code different from 200, the cells for that URL will have a value of 1; and if the request completely fails (e.g. no network connection) the cell will have a value of 2. This will allow you to analyse the failed requests.\n",
    "\n",
    "</details>\n",
    "\n",
    "**1.2** Parse the HTML retrieved to extract genre of the artist, date of birth, years active and other artist information.\n",
    "\n",
    "<details>\n",
    "\n",
    "- Write a function `singer_band_info(url, page_text)` that returns a dictionary. \n",
    "\n",
    "  Here `url` should be the the url corresponding to the singer's Wikipedia page (same as the previous dataframe `billboardtop`), and page_text should be the HTML text for the corresponding artist's webpage. This function should return a dictionary which contains the following information:\n",
    "\n",
    "  1. The genres of the band or singer. These genres should be urls, to ensure their uniqueness. Create a list, `genres`, of these urls. If there are no genres, use `['NA']`.\n",
    "\n",
    "  2. If the page has the text \"Born\", extract the element with the class `.bday`. If there is no \"Born\", store `False`. Store either of these into the variable `born`. \n",
    "\n",
    "  3. If the text \"Years active\" is found, but there is no birthday, assume a band. Store the years active into the variable `ya`, or `False` if the text is not found. \n",
    "\n",
    "  The dictionary returned should be of the form:\n",
    "  ```\n",
    "  { 'url': '/wiki/Boyz_II_Men', \n",
    "  'genres': ['/wiki/Contemporary_R%26B_music', '/wiki/Soul_music', '/wiki/New_jack_swing'], \n",
    "  'born': None, \n",
    "  'ya': '1987–present'}\n",
    "  ```\n",
    "- Once the above function is created, generate a list `singer_band_info_list` to store the information extracted above. `singer_band_info_list` should be a list of the dictionaries that the function `singer_band_info` returns. The list should look something like this:\n",
    "```\n",
    "  'genres': ['/wiki/Contemporary_R%26B_music',\n",
    "   '/wiki/Soul_music',\n",
    "   '/wiki/New_jack_swing'],\n",
    "  'url': '/wiki/Boyz_II_Men',\n",
    "  'ya': '1987–present'},\n",
    " {'born': None,\n",
    "  'genres': ['/wiki/Pop_music',\n",
    "   '/wiki/Electronica_music',\n",
    "   '/wiki/Dance_music',\n",
    "   '/wiki/Rave_music',\n",
    "   '/wiki/House_music'],\n",
    "  'url': '/wiki/KWS_(band)',\n",
    "  'ya': '1991–1994'},\n",
    " ... and so on]\n",
    "  ```\n",
    "<br>\n",
    "\n",
    "  **Note:** Wikipedia has changed it's format along the years! So observing one artist's webpage and building your function based on it will probably give you tons of errors. Here are a few issues to remember while parsing:\n",
    "\n",
    "    1. There are several artists that take a sabbatical between their active years (https://en.wikipedia.org/wiki/Tony!_Toni!_Ton%C3%A9!). To get the right data, write a function to calculate the longest period of time they were active and consider that as your variable `years active`. In the example give, this would be 2003–present.\n",
    "    2. Birthday's are given in different formats for different pages. For example - https://en.wikipedia.org/wiki/Sir_Mix-a-Lot and https://en.wikipedia.org/wiki/Ed_Sheeran have different formats. To ensure that you get the right day, look for the 'span' tag with a 'bday' tag and ensure that there are no paranthesis around the extracted text.\n",
    "    3. Year's active are also given in different formats. For example - https://en.wikipedia.org/wiki/Boyz_II_Men and https://en.wikipedia.org/wiki/Ed_Sheeran are different. You could use regex (\"[0-9]{4}[–][0-9]{4}\" and \"[0-9]{4}[–][0-9]{4}\") to ensure you are getting the right years.\n",
    "\n",
    "  Definitely do look at your outputs as you are parsing as it can identify several edge cases you have not considered in your code.\n",
    "\n",
    "</details>\n",
    "\n",
    "**Question 2:** Construct a DataFrame from parsed data\n",
    "\n",
    "**2.1** Construct a dataframe from the list `singer_band_info_list` and convert them to the correct data types if needed.\n",
    "\n",
    "<details>\n",
    "\n",
    "- Construct a dataframe from the list created in the previous section yearinfo. Name this dataframe `singerbandinfo`.\n",
    "\n",
    "  Your dataframe `singerbandinfo` should look something like this:\n",
    "\n",
    "  <img src=\"https://drive.google.com/uc?export=view&id=1LZh_J-LsB2p9UW7lCJaSbPNMTH-Bv61p\" width=1500/> \n",
    "\n",
    "- Check dataframe data types using dtypes.\n",
    "- Convert them to the correct data types if needed using the astype() function.\n",
    "\n",
    "\n",
    "</details>\n",
    "\n",
    "**2.2** Merge `billboardtop` and `singerbandinfo` to create one dataframe.\n",
    "\n",
    "<details>\n",
    "\n",
    "- Merge the artist/song data frames into one large dataframe named `finaldf` on url. Your  dataframe should look something like this:\n",
    "  <img src=\"https://drive.google.com/uc?export=view&id=1JMoV2gvIpIQ4tDGwidT7eAGKGusF8V0Z\" width=1500/> \n",
    "\n",
    "  Note that this has an effect of imputing to a song all the genres that the artist is active in. We know that this is not true, but it is the simplest assumption we can make, and is probably good for most artists.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kB54u81xJk-"
   },
   "source": [
    "### Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JuL6xVq1xN47"
   },
   "source": [
    "#### Question 1: Scrape and Parse Wikipedia for information about Artists and Bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "byvQaqnFxcHZ"
   },
   "source": [
    "**1.1** Scrape the artist's Wikipedia webpages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hint: Before you apply uour function to the dataframe, sort `billboardtop` by year. This will ensure that we will hit the cache most as singers who show up repeatedly in the rankings will have their information already pulled.\n",
    "\n",
    "This is optional from the perspective to optimization, you can choose to ignore it but then you will have higher run time at your end and you will end up writing more code to maintain data sanity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1653658771530,
     "user": {
      "displayName": "Arya Mohan",
      "userId": "15606194433450766788"
     },
     "user_tz": -330
    },
    "id": "xLIr5RLOlm8C",
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "urlcache={}\n",
    "def get_page(url):\n",
    "    if (url not in urlcache) or (urlcache[url]==1) or (urlcache[url]==2):\n",
    "        time.sleep(1)\n",
    "        try:\n",
    "            r = requests.get(\"http://en.wikipedia.org%s\" % url)\n",
    "            if r.status_code == 200:\n",
    "                urlcache[url] = r.text\n",
    "            else:\n",
    "                urlcache[url] = 1\n",
    "        except:\n",
    "            urlcache[url] = 2\n",
    "    return urlcache[url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1765677,
     "status": "ok",
     "timestamp": 1653660540815,
     "user": {
      "displayName": "Arya Mohan",
      "userId": "15606194433450766788"
     },
     "user_tz": -330
    },
    "id": "jGHEg1IDlm8O",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "df1ec7d5-b8fa-4308-9db1-8eba93d42fe4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here I am populating the url cache\n",
    "# Note that this function will take around 20 minutes to run as we are requesting for several pages\n",
    "# This function is designed to be run again and again: it just tries to make sure that there are no unresolved pages left. \n",
    "billboardtop[\"url\"].apply(get_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1653660540816,
     "user": {
      "displayName": "Arya Mohan",
      "userId": "15606194433450766788"
     },
     "user_tz": -330
    },
    "id": "vtH5ch-Jlm8X",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "380967e1-4187-4b65-d5ea-7b7372f890f9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make sure that there are no unresolved pages\n",
    "# The sum below should be 0, and the boolean True. If that is not the case, run the above cell again until you get a sum of 0 and a boolean True\n",
    "print (np.sum([(urlcache[k]==1) or (urlcache[k]==2) and isinstance(k,str) for k in urlcache]))\n",
    "print (\"Did we get all the URLs?\",len(billboardtop.url.unique())==len(urlcache))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2639,
     "status": "ok",
     "timestamp": 1653660543451,
     "user": {
      "displayName": "Arya Mohan",
      "userId": "15606194433450766788"
     },
     "user_tz": -330
    },
    "id": "u-g3mOWrlm8c",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Saving the `urlcache` and removin the old object. \n",
    "keys_values = urlcache.items()\n",
    "urlcache = {str(key): str(value) for key, value in keys_values}\n",
    "with open(\"artistinfo.json\",\"w\") as fd:\n",
    "    json.dump(urlcache, fd)\n",
    "del urlcache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3867,
     "status": "ok",
     "timestamp": 1653660547316,
     "user": {
      "displayName": "Arya Mohan",
      "userId": "15606194433450766788"
     },
     "user_tz": -330
    },
    "id": "ctcBqdEPlm8f",
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading artist info\n",
    "with open(\"artistinfo.json\") as json_file:\n",
    "    urlcache = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1653660547317,
     "user": {
      "displayName": "Arya Mohan",
      "userId": "15606194433450766788"
     },
     "user_tz": -330
    },
    "id": "aaflaMIF6N91",
    "outputId": "e5afb222-6434-4022-ee14-f3183676bd6d"
   },
   "outputs": [],
   "source": [
    "len(urlcache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_G84LnUlm8p"
   },
   "source": [
    "**1.2** Parse the HTML retrieved to extract genre of the artist, date of birth, years active and other artist information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wepOCDnV2H3p"
   },
   "source": [
    "Before parsing, it is important to note that Wikipedia has defined the same genre in a few different ways. Your parsing code will pick these up as different and new as they all differ with the alphabet case or an underscore instead of a hyphen.\n",
    "\n",
    "I am adding potential duplicates list to make the task a little easier so that the above mentioned issue does not create duplicate data under same categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1653660547317,
     "user": {
      "displayName": "Arya Mohan",
      "userId": "15606194433450766788"
     },
     "user_tz": -330
    },
    "id": "QTSJHvJF3pxu"
   },
   "outputs": [],
   "source": [
    "genres_duplicates= {'/wiki/Adult_Contemporary_music':'/wiki/Adult_contemporary',\n",
    " '/wiki/Adult_contemporary_music':'/wiki/Adult_contemporary',\n",
    "'/wiki/Afrobeat':'/wiki/Afrobeats',\n",
    "'/wiki/Alternative_rock':'/wiki/Alternative_Rock',\n",
    "'/wiki/Avant-garde':'/wiki/Avant-garde_music',\n",
    "'/wiki/Blues':'/wiki/Blues_music',\n",
    "'/wiki/Comedy_hip-hop':'/wiki/Comedy_hip_hop',\n",
    "'/wiki/Contemporary_R%26B':'/wiki/Contemporary_R%26B_music',\n",
    "'/wiki/Contemporary_folk':'/wiki/Contemporary_folk_music',\n",
    "'/wiki/Country_Folk':'/wiki/Country_folk',\n",
    "'/wiki/Dance_pop':'/wiki/Dance-pop',\n",
    "'/wiki/East_Coast_hip_hop':'/wiki/East_coast_hip_hop',\n",
    "'/wiki/Electronic_Dance_Music':'/wiki/Electronic_dance_music',\n",
    "'/wiki/Electronica':'/wiki/Electronica_music',\n",
    "'/wiki/Emo':'/wiki/Emo_music',\n",
    "'/wiki/Electropop':'/wiki/Electro-pop',\n",
    "'/wiki/Folk-pop':'/wiki/Folk_pop',\n",
    "'/wiki/Funk':'/wiki/Funk_music',\n",
    "'/wiki/Grime_(music_genre)':'/wiki/Grime_music',\n",
    "'/wiki/Gangsta_Rap':'/wiki/Gangsta_rap',\n",
    "'/wiki/Hip_Hop_music': '/wiki/Hip_hop','/wiki/Hip_hop_music':'/wiki/Hip_hop',\n",
    "'/wiki/Hyphy':'/wiki/Hyphy_music',\n",
    "'/wiki/Latin_music':'/wiki/Latin_music_(genre)',\n",
    "'/wiki/West_Coast_hip_hop':'/wiki/West_coast_hip_hop',\n",
    "'/wiki/Southern_Hip_Hop':'/wiki/Southern_hip_hop',\n",
    "'/wiki/Ska':'/wiki/Ska_music',\n",
    "'/wiki/Pop-rock':'/wiki/Pop_rock',\n",
    "'/wiki/Pop_Music':'/wiki/Pop_music',\n",
    "'/wiki/Nu_metal':'/wiki/Nu_metal_music',\n",
    "'/wiki/Hard_Rock':'/wiki/Hard_rock',\n",
    "'/wiki/Pop_Rock':'/wiki/Pop_rock',\n",
    "'/wiki/Post-Grunge':'/wiki/Post-grunge',\n",
    "'/wiki/SoundCloud_rap':'/wiki/Soundcloud_rap'}\n",
    "\n",
    "def genre_duplicates(genres):\n",
    "    for i in range(len(genres)):\n",
    "        if genres[i] in genres_duplicates.keys():\n",
    "            genres[i]=genres_duplicates[genres[i]]\n",
    "    return genres "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2.1** Define a function to calculate the longest active years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "aborted",
     "timestamp": 1653658444655,
     "user": {
      "displayName": "Arya Mohan",
      "userId": "15606194433450766788"
     },
     "user_tz": -330
    },
    "id": "iCiUaa3t1mdM"
   },
   "outputs": [],
   "source": [
    "# Start your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C30IKrh_lm89"
   },
   "source": [
    "**1.2.2** Please write the function `singer_band_info` according to the following specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "aborted",
     "timestamp": 1653658444655,
     "user": {
      "displayName": "Arya Mohan",
      "userId": "15606194433450766788"
     },
     "user_tz": -330
    },
    "id": "144RCE17lm9C",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "singer_band_info\n",
    "\n",
    "Inputs\n",
    "------\n",
    "url: the url\n",
    "page_text: the text associated with the url\n",
    "   \n",
    "Returns\n",
    "-------\n",
    "A dictionary with the following data:\n",
    "    url: copy the input argument url into this value\n",
    "    genres: the genres that the band or singer works in\n",
    "    born: the artist's birthday\n",
    "    ya: years active variable\n",
    "\n",
    "Notes\n",
    "-----\n",
    "See description above. Also note that some of the genres urls might require a \n",
    "bit of care and special handling.\n",
    "\"\"\"\n",
    "# Start your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r33k0Rv9lm9M"
   },
   "source": [
    "#### Question 2: Construct a DataFrame from parsed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFBbluyq_xUg"
   },
   "source": [
    "**2.1** Construct a dataframe from the list `singer_band_info_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "aborted",
     "timestamp": 1653658444656,
     "user": {
      "displayName": "Arya Mohan",
      "userId": "15606194433450766788"
     },
     "user_tz": -330
    },
    "id": "mvihe4PIKBkv"
   },
   "outputs": [],
   "source": [
    "# Start your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipg0V9b5ILZ9"
   },
   "source": [
    "**2.2** Merge billboardtop and singerbandinfo to create one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "aborted",
     "timestamp": 1653658444656,
     "user": {
      "displayName": "Arya Mohan",
      "userId": "15606194433450766788"
     },
     "user_tz": -330
    },
    "id": "zXmWArJllm9h",
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mdmfw0ZIGlG5"
   },
   "source": [
    "# Part C: Exploratory Data Analysis (EDA)\n",
    "\n",
    "**Question 1:** What has been the trajectory of various genres in the popular zeitgeist?<br>\n",
    "\n",
    "**1.1** What are the 30 most popular genres?<br>\n",
    "\n",
    "<details>\n",
    "\n",
    "1.1.1 Find the top 30 genres and plot a bar plot of these genres.<br>\n",
    "1.1.2 Feel free to plot any other visualizations that you can think of!<br>\n",
    "1.1.3 Calculate the mean of the dataframe and eliminate the first two columns (`year` and `ranking`) to get means of all the genre columns.<br>\n",
    "1.1.4 Sort it in ascending order and pick the top 30.<br>\n",
    "\n",
    "</details>\n",
    "\n",
    "**1.2** How has the popularity of these 30 genres changed with time?<br>\n",
    "\n",
    "<details>\n",
    "\n",
    "1.2.1 Create a subframe of the ranking and year for each genre.<br>\n",
    "1.2.2 Groupby() function to group by year to create a dataframe that contains the rankings of every song from that genre in a given year.<br>\n",
    "\n",
    "</details>\n",
    "\n",
    "**Question 2:** Who are the highest quality singers?<br>\n",
    "\n",
    "**2.1** Who are the most occurring artists in Billboard's Top 100 list?<br>\n",
    "\n",
    "<details>\n",
    "\n",
    "2.1.1 Count the number of times a singer appears in the top 100 over a certain time period. Consider an artist appearing twice in a year as two appearances.<br>\n",
    "\n",
    "2.1.2 Plot a bar chart of the artists who have occurred at least more than 15 times in the given time frame.<br>\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "\n",
    "**2.3**  What is the age at which singers achieve their top ranking?<br>\n",
    "\n",
    "<details>\n",
    "\n",
    "* Plot a histogram of the age at which artists reach their top ranking.<br>\n",
    "\n",
    "</details>\n",
    "\n",
    "**2.4** At what year since inception do bands reach their top rankings?<br>\n",
    "\n",
    "<details>\n",
    "\n",
    "* Make a similar calculation to plot a histogram of the years since inception at which bands reach their top ranking.<br>\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vP4btHmCGlHf"
   },
   "source": [
    "### Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start your code here\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Kd_0dzuslm7B",
    "QmtbYTjl8rR0",
    "r33k0Rv9lm9M"
   ],
   "name": "HW1_Solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
